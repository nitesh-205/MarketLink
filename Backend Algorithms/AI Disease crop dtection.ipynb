{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pepper__bell___Bacterial_spot',\n",
       " 'Pepper__bell___healthy',\n",
       " 'Potato___Early_blight',\n",
       " 'Potato___Late_blight',\n",
       " 'Potato___healthy',\n",
       " 'Tomato_Bacterial_spot',\n",
       " 'Tomato_Early_blight',\n",
       " 'Tomato_Late_blight',\n",
       " 'Tomato_Leaf_Mold',\n",
       " 'Tomato_Septoria_leaf_spot',\n",
       " 'Tomato_Spider_mites_Two_spotted_spider_mite',\n",
       " 'Tomato__Target_Spot',\n",
       " 'Tomato__Tomato_YellowLeaf__Curl_Virus',\n",
       " 'Tomato__Tomato_mosaic_virus',\n",
       " 'Tomato_healthy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_height, img_width = 128, 128\n",
    "batch_size = 32\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.452771931886673, 0.46341875195503235, 0.4189051687717438], std=[0.15574541687965393, 0.13233783841133118, 0.17319917678833008])\n",
    "])\n",
    "\n",
    "valid_transforms = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.452771931886673, 0.46341875195503235, 0.4189051687717438], std=[0.15574541687965393, 0.13233783841133118, 0.17319917678833008])\n",
    "])\n",
    "\n",
    "train_data_dir = r'C:\\Users\\dnite\\Projects\\PlantVillage\\train'\n",
    "full_dataset = datasets.ImageFolder(train_data_dir, transform=train_transforms)\n",
    "\n",
    "val_size = int(0.2 * len(full_dataset))\n",
    "train_size = len(full_dataset) - val_size\n",
    "train_dataset, val_dataset = random_split(full_dataset, [train_size, val_size])\n",
    "\n",
    "val_dataset.dataset.transform = valid_transforms\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "test_data_dir = r'C:\\Users\\dnite\\Projects\\PlantVillage\\val'\n",
    "test_dataset = datasets.ImageFolder(test_data_dir, transform=valid_transforms)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=4)\n",
    "\n",
    "class_names = full_dataset.classes\n",
    "class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (5): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (6): ReLU()\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (9): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (10): ReLU()\n",
      "    (11): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=32768, out_features=128, bias=True)\n",
      "    (2): ReLU()\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=15, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 128 -> 64\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 64 -> 32\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2)   # 32 -> 16\n",
    "        )\n",
    "        # Вычисляем размер признакового вектора: 128 каналов, размер 16x16 (при входе 128x128)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128 * (img_height // 8) * (img_width // 8), 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "num_classes = len(class_names)\n",
    "model = CNN(num_classes).to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: Train Loss: 1.2345, Train Acc: 0.5927 | Val Loss: 0.5892, Val Acc: 0.8026\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = CNN(num_classes=15).to(device)\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate, momentum=0.9)\n",
    "\n",
    "best_val_loss = np.inf\n",
    "patience = 5\n",
    "trigger_times = 0\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    train_loss = running_loss / total\n",
    "    train_acc = correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    \n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "    val_loss = val_loss / total_val\n",
    "    val_acc = correct_val / total_val\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "    \n",
    "    print(f\"Epoch {epoch}/{epochs}: Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f} | Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n",
    "    \n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        trigger_times = 0\n",
    "    else:\n",
    "        trigger_times += 1\n",
    "        if trigger_times >= patience:\n",
    "            print(\"Early stopping\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import torch  # Assuming you're using PyTorch\n",
    "\n",
    "# Load the best saved model\n",
    "model = CNN(num_classes=15).to(device)  # make sure 15 matches your class count\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "# Disable gradient calculation (inference mode)\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        outputs = model(images)\n",
    "        _, preds = torch.max(outputs, 1)  # Get predicted class\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.numpy())\n",
    "\n",
    "# Compute confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Print a detailed classification report (precision, recall, f1-score, and support for each class)\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "# Function to denormalize an image (return to range [0, 1])\n",
    "def denormalize(img):\n",
    "    img = img * 0.5 + 0.5  # reverse normalization with mean=0.5, std=0.5\n",
    "    return img\n",
    "\n",
    "# Select a few random images from the test dataset\n",
    "model.eval()\n",
    "plt.figure(figsize=(12, 8))\n",
    "num_images = 9\n",
    "for i in range(num_images):\n",
    "    idx = random.randint(0, len(test_dataset) - 1)\n",
    "    img, label = test_dataset[idx]\n",
    "    \n",
    "    # Add batch dimension and move to device\n",
    "    img_input = img.unsqueeze(0).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(img_input)\n",
    "        _, pred = torch.max(output, 1)\n",
    "    \n",
    "    pred_class = class_names[pred.item()]\n",
    "    true_class = class_names[label]\n",
    "    \n",
    "    plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(np.transpose(denormalize(img).numpy(), (1, 2, 0)))\n",
    "    plt.title(f\"Pred: {pred_class}\\nTrue: {true_class}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "result = {\n",
    "    \"detected_crop\": \"Tomato\",\n",
    "    \"health_status\": \"Healthy\"\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "with open(\"output/crop_detection_result.json\", \"w\") as f:\n",
    "    json.dump(result, f)\n",
    "\n",
    "# ✅ Show result in Jupyter output\n",
    "print(\"✅ Detection Result Saved:\")\n",
    "print(json.dumps(result, indent=4))  # Nicely formatted output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 619181,
     "sourceId": 1105687,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30920,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
